diff --git a/common.py b/common.py
index 35bb948..ed6cb46 100644
--- a/common.py
+++ b/common.py
@@ -154,7 +154,7 @@ def findValue(value: int, searchList: list, index=0):
         return (False, None)
     return (False, None)
 
-def getVerbGNP(tam, depend_data, processed_nouns, processed_pronouns):
+def getVerbGNP_old(tam, depend_data, processed_nouns, processed_pronouns):
     ''' Return GNP information of processed_noun/processed_pronoun which
     has k1 in dependency row. But if verb has tam = yA , then GNP information
     is given of that processed_noun/processed_pronoun which has k2 in dependency row.
@@ -195,11 +195,11 @@ def getComplexP

     return gender, number, person
 
-def getVerbGNP_new(verbs_data, seman_data, depend_data, sentence_type, processed_nouns, processed_pronouns):
+def getVerbGNP(verbs_data, seman_data, depend_data, sentence_type, processed_nouns, processed_pronouns):
     '''
     '''
 
-    if sentence_type == 'Imperative':
+    if sentence_type in ('Imperative', 'imperative') :
         verb_gender = 'm'
         verb_number = 's'
         verb_person = 'm'
@@ -207,7 +207,7 @@ def getVerbGNP_new(verbs_data, seman_data, depend_data, sentence_type, processed
 
     #if non-imperative sentences, then do rest of the processing
     unprocessed_main_verb = verbs_data
-    main_verb = identify_main_verb(unprocessed_main_verb)
+    #main_verb = identify_main_verb(unprocessed_main_verb)
     is_cp = is_CP(unprocessed_main_verb)
     tam = identify_default_tam_for_main_verb(unprocessed_main_verb)
     k1exists = False
@@ -332,7 +332,6 @@ def auxmap_hin(aux_verb):
         log('Auxillary Mapping File not found.', 'ERROR')
         sys.exit()
 
-
 def check_noun(word_data):
     '''Check if word is a noun by the USR info'''
 
@@ -412,7 +411,6 @@ def check_verb(word_data):
                 return True
     return False
 
-
 def check_adverb(word_data):
     '''Check if word is an adverb by the USR info. Check for kr_vn in dependency row.
     '''
@@ -450,6 +448,7 @@ def analyse_words(words_list):
     verbs = []
     others = []
     adverbs = []
+    nominal_form = []
 
     for word_data in words_list:
         if check_indeclinable(word_data):
@@ -461,6 +460,9 @@ def analyse_words(words_list):
         elif check_adverb(word_data):
             log(f'{word_data[1]} identified as adverb.')
             adverbs.append(word_data)
+        elif check_nominal_form(word_data):
+            log(f'{word_data[1]} identified as nominal form.')
+            nominal_form.append(word_data)
         elif check_pronoun(word_data):
             log(f'{word_data[1]} identified as pronoun.')
             pronouns.append(word_data)
@@ -474,8 +476,39 @@ def analyse_words(words_list):
             log(f'{word_data[1]} identified as other word, but processed as noun with default GNP.')  # treating other words as noun
             # others.append(word_data) #modification by Kirti on 12/12 to handle other words
             nouns.append(word_data)
-    return indeclinables, pronouns, nouns, adjectives, verbs, adverbs, others
+    return indeclinables, pronouns, nouns, adjectives, verbs, adverbs, others, nominal_form
+
 
+def check_nominal_form(word_data):
+    rel_list = ['rt', 'rh', 'k7p', 'k7t']
+    relation = word_data[4].strip().split(':')[1]
+    gnp_info = word_data[3]
+    if relation in rel_list and gnp_info == '':
+        return True
+    return False
+
+def process_nominal_form(nominal_forms_data, processed_noun):
+    #index, clean_dnouns, category, case, gender, number, person, noun_type, postposition
+    nominal_verbs = []
+    for nominal_form in nominal_forms_data:
+        index = nominal_form[0]
+        term = clean(nominal_form[1])
+        gender = 'm'
+        number = 's'
+        person = 'a'
+        category = 'n'
+        noun_type = 'vn'
+        case = 'o'
+        postposition = ''
+        tags = find_tags_from_dix_as_list(term)
+        for tag in tags:
+            if (tag[0] == 'cat' and tag[1] == 'v'):
+                processed_noun.append(index, term, category, case, gender, number, person, noun_type, postposition)
+                log(f'{term} processed as nominal verb with index {index} gen:{gender} num:{number} person:{person} noun_type:{noun_type} case:{case} and postposition:{postposition}')
+            else:
+                log('when cat is not v')
+
+    return nominal_verbs
 
 def process_adverb_as_noun(concept):
     index = concept[0]
@@ -561,7 +594,6 @@ def extract_gnp(gnp_info):
 
     return gender, number, person
 
-
 def process_pronouns(pronouns, processed_nouns):
     '''Process pronouns as (index, word, category, case, gender, number, person, parsarg, fnum)'''
     processed_pronouns = []
@@ -604,7 +636,7 @@ def process_pronouns(pronouns, processed_nouns):
 
 
 def process_nouns(nouns):
-    '''Process nouns as (index, word, category, case, gender, number, proper/noun type= proper or CP_noun, postposition)'''
+    '''Process nouns as (index, word, category, case, gender, number, proper/noun type= proper, common, NC, nominal_verb or CP_noun, postposition)'''
     #noun_attribute dict to store all nouns as keys
     processed_nouns = []
     for noun in nouns:
@@ -654,7 +686,7 @@ def process_adjectives(adjectives, processed_nouns):
         relnoun = int(adjective[4].strip().split(':')[0])
         relnoun_data = getDataByIndex(relnoun, processed_nouns)
         category = 'adj'
-        if relnoun_data != True:
+        if relnoun_data == ():
             log(f'Associated noun not found with the adjective {adjective[1]}. Using default m,s,a,o ')
         else:
             case = relnoun_data[3]
@@ -664,9 +696,6 @@ def process_adjectives(adjectives, processed_nouns):
         noun = relnoun_data[1]
         add_adj_to_noun_attribute(noun, adj)
         processed_adjectives.append((adjective[0], adj, category, case, gender, number))
-
-
-
         log(f'{adjective[1]} processed as an adjective with case:{case} gen:{gender} num:{number}')
     return processed_adjectives
 
@@ -797,7 +826,7 @@ def process_main_verb(concept: Concept, seman_data, dependency_data, sentence_ty
         verb.term = alt_root[verb.tam]  # handling past tense by passing correct root WA
         verb.tam = alt_tam[verb.tam]
     verb.tam = get_TAM(verb.term, verb.tam)
-    verb.gender, verb.number, verb.person = getVerbGNP_new(concept.term, seman_data, dependency_data, sentence_type, processed_nouns, processed_pronouns)
+    verb.gender, verb.number, verb.person = getVerbGNP(concept.term, seman_data, dependency_data, sentence_type, processed_nouns, processed_pronouns)
     if is_CP(concept.term):
         if not reprocessing:
             CP = process_main_CP(concept.index, concept.term)
@@ -1035,6 +1064,8 @@ def generate_input_for_morph_generator(input_data):
                 morph_data = f'^{data[1]}<cat:{data[2]}><case:{data[3]}><parsarg:{data[7]}><gen:{data[4]}><num:{data[5]}><per:{data[6]}>$'
         elif data[2] == 'n' and data[7] == 'proper':
             morph_data = f'{data[1]}'
+        elif data[2] == 'n' and data[7] == 'vn':
+            morph_data = f'^{data[1]}<cat:{data[7]}><case:{data[3]}>$'
         elif data[2] == 'n' and data[7] != 'proper':
             morph_data = f'^{data[1]}<cat:{data[2]}><case:{data[3]}><gen:{data[4]}><num:{data[5]}>$'
         elif data[2] == 'v' and data[8] in ('main','auxillary'):
diff --git a/generate_input_modularize_new.py b/generate_input_modularize_new.py
index 3675287..459c16d 100644
--- a/generate_input_modularize_new.py
+++ b/generate_input_modularize_new.py
@@ -30,7 +30,7 @@ if __name__ == "__main__":
                     gnp_data, depend_data, discourse_data, spkview_data, scope_data)
     
     # Categorising words as Nound/Pronouns/Adjectives/..etc.
-    indeclinables_data, pronouns_data, nouns_data, adjectives_data, verbs_data, adverbs_data, others_data = analyse_words(words_info)
+    indeclinables_data, pronouns_data, nouns_data, adjectives_data, verbs_data, adverbs_data, others_data, nominal_forms_data = analyse_words(words_info)
     
     #  Processing Stage
     processed_indeclinables = process_indeclinables(indeclinables_data)
@@ -40,6 +40,7 @@ if __name__ == "__main__":
     processed_others = process_others(others_data)
     processed_verbs, processed_auxverbs= process_verbs(verbs_data, seman_data, depend_data, sentence_type, processed_nouns, processed_pronouns, False)
     process_adverbs(adverbs_data, processed_nouns, processed_verbs, processed_others)
+    process_nominal_form = process_nominal_form(nominal_forms_data, processed_nouns)
     
     # Todo : extract nouns / adjectives from Compound verbs with +
     # Todo : process nouns / adjectives got from verbs and add to processed_noun / processed_adjectives
diff --git a/verified_sent/101 b/verified_sent/101
index 3ac83f6..1f1dfdf 100644
--- a/verified_sent/101
+++ b/verified_sent/101
@@ -1,5 +1,5 @@
 #viveka ne rAhula ko BI samAroha meM AmaMwriwa kiyA.
-vivek, rahul, samAroha_3, AmaMwriwa+kara_1-yA_1
+viveka, rAhula, samAroha_3, AmaMwriwa+kara_1-yA_1
 1,2,3,4
 per,per,,
 [m sg a],[m sg a],,,
